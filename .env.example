# Example environment template (no secrets)
# Copy this to .env and fill in your actual values

# OpenAI Configuration
OPENAI_API_KEY=YOUR_OPENAI_API_KEY_HERE

# Models (use current docs to pick names)
# Valid realtime models include 'gpt-4o-realtime-preview' (update as needed)
OPENAI_REALTIME_MODEL=gpt-realtime-mini-2025-10-06
OPENAI_TEXT_MODEL=gpt-4o-mini
# Allowed voices: alloy, ash, ballad, coral, echo, sage, shimmer, verse, marin, cedar
OPENAI_TTS_VOICE=cedar
# Transcription model for realtime voice input (optimized low-latency model)
OPENAI_TRANSCRIPTION_MODEL=gpt-4o-mini-transcribe

# Voice activity detection tuning (lower values reduce end-of-turn lag)
# REALTIME_VAD_THRESHOLD sets sensitivity (0..1) - lower = more sensitive
# REALTIME_VAD_PREFIX_MS = audio captured BEFORE speech detected (prevents word cutoff)
# REALTIME_VAD_SILENCE_MS = silence duration before turn ends
# Tuned for clear transcription: higher prefix to capture beginning of speech
REALTIME_VAD_THRESHOLD=0.30
REALTIME_VAD_PREFIX_MS=1000
REALTIME_VAD_SILENCE_MS=800

# Database Configuration
DATABASE_URL=file:./dev.db

# Feature flags
VOICE_ENABLED=true
BANNERS_ENABLED=true
NEGOTIATOR_ENABLED=false
GRADING_ENABLED=false

# Server Configuration
PORT=3002
NODE_ENV=development

# CORS & Origins (adjust for your deployment)
FRONTEND_ORIGIN=http://localhost:5173
BACKEND_ORIGIN=http://localhost:3002
CORS_ALLOWED_ORIGINS=http://localhost:5173
